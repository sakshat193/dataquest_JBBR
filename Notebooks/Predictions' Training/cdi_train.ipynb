{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get dataset directory\n",
    "dataset_dir = os.getenv(\"DATASET_DIR\")\n",
    "if dataset_dir is None:\n",
    "    raise ValueError(\"DATASET_DIR not found in .env file\")\n",
    "\n",
    "# Use pathlib for reliable path handling\n",
    "data_file = Path(dataset_dir) / \"3_earthquake_1995-2023.csv\"\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(columns=['title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualize CDI distribution\n",
    "sns.histplot(df['cdi'], kde=True, bins=30)\n",
    "plt.title('Distribution of CDI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['cdi'])\n",
    "y = df['cdi']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Initialize transformers dictionary\n",
    "transformers = {\n",
    "    'label_encoders': {},\n",
    "    'scaler': StandardScaler(),\n",
    "    'target_encoder': LabelEncoder()  # Added target encoder\n",
    "}\n",
    "\n",
    "# Create copy of X for transformation\n",
    "X_transformed = X.copy()\n",
    "\n",
    "# Transform categorical features\n",
    "for cat_col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    X_transformed[cat_col] = le.fit_transform(X[cat_col])\n",
    "    transformers['label_encoders'][cat_col] = le\n",
    "\n",
    "# Transform numerical features\n",
    "if len(numerical_features) > 0:\n",
    "    X_transformed[numerical_features] = transformers['scaler'].fit_transform(X[numerical_features])\n",
    "\n",
    "# Transform target variable\n",
    "y_transformed = transformers['target_encoder'].fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_transformed, y_transformed, test_size=0.2, random_state=42, stratify=y_transformed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "transformers['smote'] = smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Models directory\n",
    "models_dir = Path.cwd() / \"Models\"\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save transformers\n",
    "with open(models_dir / 'transformers.pkl', 'wb') as f:\n",
    "    pickle.dump(transformers, f)\n",
    "\n",
    "# Save feature information\n",
    "feature_info = {\n",
    "    'categorical_features': list(categorical_features),\n",
    "    'numerical_features': list(numerical_features)\n",
    "}\n",
    "\n",
    "with open(models_dir / 'feature_info.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_info, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE, SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RFC for feature selection\n",
    "feature_selector_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfe = RFE(estimator=feature_selector_rf, n_features_to_select=5)\n",
    "kbest = SelectKBest(score_func=mutual_info_classif, k=5)\n",
    "\n",
    "# Fit feature selectors\n",
    "rfe.fit(X_train_resampled, y_train_resampled)\n",
    "kbest.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get selected features\n",
    "selected_features_rfe = X_train.columns[rfe.support_]\n",
    "selected_features_kbest = X_train.columns[kbest.get_support()]\n",
    "\n",
    "# Initialize RFC for feature importance\n",
    "rf_importance = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_importance.fit(X_train_resampled, y_train_resampled)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_importance.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "selected_features_rf = feature_importance.head(5)['Feature']\n",
    "\n",
    "print(\"\\nSelected Features:\")\n",
    "print(f\"RFE: {list(selected_features_rfe)}\")\n",
    "print(f\"SelectKBest: {list(selected_features_kbest)}\")\n",
    "print(f\"Random Forest Importance: {list(selected_features_rf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final selected features (using RF importance)\n",
    "selected_features = list(selected_features_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save selected features\n",
    "with open(models_dir / 'selected_features.pkl', 'wb') as f:\n",
    "    pickle.dump(selected_features, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare final datasets\n",
    "X_train_final = X_train_resampled[selected_features]\n",
    "X_test_final = X_test[selected_features]\n",
    "\n",
    "# Define RFC parameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RFC\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rfc,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train_final, y_train_resampled)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-validation Score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = best_rf.predict(X_test_final)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "with open(models_dir / 'cdi_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_rf, f)\n",
    "\n",
    "print(f\"\\nBest Random Forest model saved in {models_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
